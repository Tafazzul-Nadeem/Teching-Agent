{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38739aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86d9e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Optional, Annotated, List, Sequence, Dict\n",
    "import operator\n",
    "\n",
    "class AgentInputState(MessagesState):\n",
    "    pass\n",
    "\n",
    "class AgentState(MessagesState):\n",
    "    \"\"\"\n",
    "    Main state for the full multi-agent research system.\n",
    "    \n",
    "    Extends MessagesState with additional fields for research coordination.\n",
    "    Note: Some fields are duplicated across different state classes for proper\n",
    "    state management between subgraphs and the main workflow.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input message generated from user conversation history\n",
    "    input_message: List[Dict[str, str]]\n",
    "    diagram_type: str\n",
    "    mermaid_code: str\n",
    "    entity_names: list[str] = []\n",
    "    edge_labels: list[str] = []\n",
    "    bit_ranges: list[str] = []\n",
    "\n",
    "    # # Messages exchanged with the supervisor agent for coordination\n",
    "    # supervisor_messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    # # Raw unprocessed research notes collected during the research phase\n",
    "    # raw_notes: Annotated[list[str], operator.add] = []\n",
    "    # # Processed and structured notes ready for report generation\n",
    "    # notes: Annotated[list[str], operator.add] = []\n",
    "    # # Final formatted research report\n",
    "    # final_report: str\n",
    "\n",
    "# ===== STRUCTURED OUTPUT SCHEMAS =====\n",
    "class StartMessageState(BaseModel):\n",
    "    \"\"\"Schema for invoking the supervisor agent.\"\"\"\n",
    "    diagram_type: str = Field(\n",
    "        description=\"Type of diagram provided by the user\"\n",
    "    )\n",
    "class OCRStateEntities(BaseModel):\n",
    "    \"\"\"Schema for invoking the OCR agent.\"\"\"\n",
    "    entity_names: List[str] = Field(\n",
    "        description=\"Names of entities detected in the image\"\n",
    "    )\n",
    "    edge_labels: List[str] = Field(\n",
    "        description=\"Labels of the edges detected in the image\"\n",
    "    )\n",
    "class OCRStateEdges(BaseModel):\n",
    "    \"\"\"Schema for invoking the OCR agent.\"\"\"\n",
    "    edge_labels: List[str] = Field(\n",
    "        description=\"Labels of the edges detected in the image\"\n",
    "    )\n",
    "    bit_ranges: List[str] = Field(\n",
    "        description=\"Bit ranges of the headers detected in the image\"\n",
    "    )\n",
    "class CodeAgentState(BaseModel):\n",
    "    \"\"\"Schema for invoking the Code agent.\"\"\"\n",
    "    mermaid_code: str = Field(\n",
    "        description=\"Mermaid code generated by the agent\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bd784e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing_extensions import Literal\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, AIMessage, get_buffer_string\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Command\n",
    "from prompts.mermaid_examples import mermaid_example\n",
    "from prompts.prompts import supervisor_get_diag, ocr_extract_entity, write_mermaid, ocr_extract_edges\n",
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize model\n",
    "# model = init_chat_model(model=\"openai:gpt-4.1\", temperature=0.0)\n",
    "model = init_chat_model(model=\"openai:gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "\n",
    "# ===== WORKFLOW NODES =====\n",
    "\n",
    "def supervisor_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Supervisor agent node that reviews research progress and provides feedback.\n",
    "    \"\"\"\n",
    "    # Combine all messages for context\n",
    "    structured_output_model = model.with_structured_output(StartMessageState)\n",
    "    \n",
    "    # response = structured_output_model.invoke([\n",
    "    #     HumanMessage(content=first_prompt.format(\n",
    "    #         messages=get_buffer_string(messages=state[\"messages\"])\n",
    "    #     ))\n",
    "    # ])\n",
    "    response = structured_output_model.invoke([*state[\"messages\"], \n",
    "        HumanMessage(content=supervisor_get_diag)\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"diagram_type\": response.diagram_type\n",
    "    }\n",
    "\n",
    "def ocr_agent_entity(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    OCR agent node that extracts text from an image.\n",
    "    \"\"\"\n",
    "    structured_output_model = model.with_structured_output(OCRStateEntities)\n",
    "    response = structured_output_model.invoke([*state[\"messages\"], \n",
    "        HumanMessage(content=ocr_extract_entity[state[\"diagram_type\"]])\n",
    "    ])\n",
    "    response.entity_names = [x.strip() for x in response.entity_names if x.strip()]\n",
    "    print(\"Extracted Entity Names:\", response.entity_names)    \n",
    "    return {\n",
    "        \"entity_names\": response.entity_names\n",
    "    }\n",
    "\n",
    "def ocr_agent_edge(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    OCR agent node that extracts edges and bit ranges.\n",
    "    \"\"\"\n",
    "    structured_output_model = model.with_structured_output(OCRStateEdges)\n",
    "    response = structured_output_model.invoke([*state[\"messages\"], \n",
    "        HumanMessage(content=ocr_extract_edges[state[\"diagram_type\"]])\n",
    "    ])\n",
    "    response.bit_ranges = [x.strip() for x in response.bit_ranges if x.strip()]\n",
    "    response.edge_labels = [x.strip() for x in response.edge_labels if x.strip()]\n",
    "    print(\"Extracted Edge Labels:\", response.edge_labels)\n",
    "    print(\"Extracted Bit Ranges:\", response.bit_ranges)    \n",
    "    return {\n",
    "        \"edge_labels\": response.edge_labels,\n",
    "        \"bit_ranges\": response.bit_ranges\n",
    "    }\n",
    "def code_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Code generation agent node that creates mermaid code from user request.\n",
    "    \"\"\"\n",
    "    structured_output_model = model.with_structured_output(CodeAgentState)\n",
    "    response = structured_output_model.invoke([*state[\"messages\"], \n",
    "        HumanMessage(content=write_mermaid.format(\n",
    "            diagram_type=state[\"diagram_type\"],\n",
    "            examples=mermaid_example[state[\"diagram_type\"]],\n",
    "            entity_names=state[\"entity_names\"],\n",
    "            edge_labels=state[\"edge_labels\"],\n",
    "            bit_ranges=state[\"bit_ranges\"]  \n",
    "        ))\n",
    "    ])\n",
    "    return {\n",
    "        \"mermaid_code\": response.mermaid_code\n",
    "    }\n",
    "\n",
    "\n",
    "# Build the scoping workflow\n",
    "teching_graph = StateGraph(AgentState, input_schema=AgentInputState)\n",
    "teching_graph.add_node(\"supervisor_node\", supervisor_node)\n",
    "teching_graph.add_node(\"ocr_agent_entity\", ocr_agent_entity)\n",
    "teching_graph.add_node(\"ocr_agent_edge\", ocr_agent_edge)\n",
    "teching_graph.add_node(\"code_agent\", code_agent)\n",
    "\n",
    "teching_graph.add_edge(START, \"supervisor_node\")\n",
    "teching_graph.add_edge(\"supervisor_node\", \"ocr_agent_entity\")\n",
    "teching_graph.add_edge(\"ocr_agent_entity\", \"ocr_agent_edge\")\n",
    "teching_graph.add_edge(\"ocr_agent_edge\", \"code_agent\")\n",
    "teching_graph.add_edge(\"code_agent\", END)\n",
    "teching_graph_workflow = teching_graph.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fb1bd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Entity Names: ['Source Port', 'Destination Port', 'Sequence Number', 'Data', 'Reserved', 'Flag', 'Checksum', 'Flag', 'Data Offset']\n",
      "Extracted Edge Labels: ['Source Port', 'Destination Port', 'Sequence Number', 'Reserved', 'Checksum', 'Data Offset']\n",
      "Extracted Bit Ranges: ['0-10', '10-20', '21-33', '33-40', '47-57', '57-80']\n",
      "```mermaid\n",
      "packet-beta\n",
      "    0-10: \"Source Port\"\n",
      "    10-20: \"Destination Port\"\n",
      "    21-33: \"Sequence Number\"\n",
      "    33-40: \"Reserved\"\n",
      "    40-47: \"Flag\"\n",
      "    47-57: \"Checksum\"\n",
      "    57-80: \"Data Offset\"\n",
      "    80-100: \"Data\"\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "img_path = Path(\"40.jpg\")\n",
    "if not img_path.exists():\n",
    "    raise FileNotFoundError(\"40.jpg not found in the current working directory\")\n",
    "\n",
    "b64 = base64.b64encode(img_path.read_bytes()).decode(\"ascii\")\n",
    "data_uri = f\"data:image/jpeg;base64,{b64}\"\n",
    "\n",
    "first_message = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\": \"Give mermaid code of the given diagram.\"},\n",
    "    {\"type\": \"image_url\", \"image_url\": {\"url\": data_uri}}\n",
    "])\n",
    "\n",
    "# result = teching_graph_workflow.invoke({\"messages\": [HumanMessage(content=\"I want to research the best coffee shops in\")]}, config=thread)\n",
    "result = teching_graph_workflow.invoke({\"messages\": first_message})\n",
    "print(result[\"mermaid_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6850e1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packet\n",
      "['Source Port', 'Destination Port', 'Sequence Number', 'Reserved', 'Flag', 'Checksum', 'Data Offset']\n",
      "['Source Port', 'Destination Port', 'Sequence Number', 'Reserved', 'Checksum', 'Data Offset']\n"
     ]
    }
   ],
   "source": [
    "print(result[\"diagram_type\"])\n",
    "print(result[\"entity_names\"])\n",
    "print(result[\"edge_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd887579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

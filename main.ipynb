{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38739aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Optional, Annotated, List, Sequence, Dict\n",
    "import operator\n",
    "\n",
    "class AgentInputState(MessagesState):\n",
    "    pass\n",
    "\n",
    "class AgentState(MessagesState):\n",
    "    \"\"\"\n",
    "    Main state for the full multi-agent research system.\n",
    "    \n",
    "    Extends MessagesState with additional fields for research coordination.\n",
    "    Note: Some fields are duplicated across different state classes for proper\n",
    "    state management between subgraphs and the main workflow.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input message generated from user conversation history\n",
    "    input_message: List[Dict[str, str]]\n",
    "    diagram_type: str\n",
    "    mermaid_code: str\n",
    "\n",
    "    # # Messages exchanged with the supervisor agent for coordination\n",
    "    # supervisor_messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    # # Raw unprocessed research notes collected during the research phase\n",
    "    # raw_notes: Annotated[list[str], operator.add] = []\n",
    "    # # Processed and structured notes ready for report generation\n",
    "    # notes: Annotated[list[str], operator.add] = []\n",
    "    # # Final formatted research report\n",
    "    # final_report: str\n",
    "\n",
    "# ===== STRUCTURED OUTPUT SCHEMAS =====\n",
    "class StartMessageState(BaseModel):\n",
    "    \"\"\"Schema for invoking the supervisor agent.\"\"\"\n",
    "    \n",
    "    mermaid_code: str = Field(\n",
    "        description=\"Mermaid code of the given image\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd784e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph TD;\n",
      "    A[0] -->|10| B[Source Port];\n",
      "    B -->|10| C[Destination Port];\n",
      "    C -->|11| D[Sequence Number];\n",
      "    D -->|7| E[Data];\n",
      "    E -->|8| F[Reserved];\n",
      "    F -->|6| G[Flag];\n",
      "    G -->|7| H[Checksum];\n",
      "    H -->|5| I[Flag];\n",
      "    I -->|10| J[Data Offset];\n",
      "    J -->|23| K[80];\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from typing_extensions import Literal\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, AIMessage, get_buffer_string\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Command\n",
    "from prompts.mermaid_examples import first_prompt\n",
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize model\n",
    "# model = init_chat_model(model=\"openai:gpt-4.1\", temperature=0.0)\n",
    "model = init_chat_model(model=\"openai:gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "\n",
    "# ===== WORKFLOW NODES =====\n",
    "\n",
    "def supervisor_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Supervisor agent node that reviews research progress and provides feedback.\n",
    "    \"\"\"\n",
    "    # Combine all messages for context\n",
    "    structured_output_model = model.with_structured_output(StartMessageState)\n",
    "    \n",
    "    # response = structured_output_model.invoke([\n",
    "    #     HumanMessage(content=first_prompt.format(\n",
    "    #         messages=get_buffer_string(messages=state[\"messages\"])\n",
    "    #     ))\n",
    "    # ])\n",
    "    response = structured_output_model.invoke(state[\"messages\"])\n",
    "    \n",
    "    return {\n",
    "        \"mermaid_code\": response.mermaid_code\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Build the scoping workflow\n",
    "teching_graph = StateGraph(AgentState, input_schema=AgentInputState)\n",
    "teching_graph.add_node(\"supervisor_node\", supervisor_node)\n",
    "teching_graph.add_edge(START, \"supervisor_node\")\n",
    "teching_graph.add_edge(\"supervisor_node\", END)\n",
    "teching_graph_workflow = teching_graph.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb1bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = Path(\"40.jpg\")\n",
    "if not img_path.exists():\n",
    "    raise FileNotFoundError(\"40.jpg not found in the current working directory\")\n",
    "\n",
    "b64 = base64.b64encode(img_path.read_bytes()).decode(\"ascii\")\n",
    "data_uri = f\"data:image/jpeg;base64,{b64}\"\n",
    "\n",
    "first_message = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\": \"Give mermaid code of the given diagram.\"},\n",
    "    {\"type\": \"image_url\", \"image_url\": {\"url\": data_uri}}\n",
    "])\n",
    "\n",
    "# result = teching_graph_workflow.invoke({\"messages\": [HumanMessage(content=\"I want to research the best coffee shops in\")]}, config=thread)\n",
    "result = teching_graph_workflow.invoke({\"messages\": first_message})\n",
    "print(result[\"mermaid_code\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
